{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74996da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "# Path to workspace\n",
    "sys.path.insert(0, '/workspace/3d-shapes-embeddings/contrib/sharp_features/')\n",
    "sys.path.insert(0, '/workspace/dense-self-supervised-representation-learning-for-3D-shapes/')\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee963e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device1, device2, device = 'cuda:3', 'cuda:3', 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bac8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, default_collate, DataLoader\n",
    "from enum import Enum\n",
    "\n",
    "class Modality(Enum):\n",
    "    MESH = 'mesh'\n",
    "    POINT_CLOUD = 'point_cloud'\n",
    "    DEPTH_IMG = 'depth_images'\n",
    "    SDF = 'sdf'\n",
    "\n",
    "\n",
    "class CrossmodalDataset(Dataset):\n",
    "    def __init__(self, data_path, modality, transform=None):\n",
    "        super().__init__()\n",
    "        self.modality = modality\n",
    "        self.transform = transform\n",
    "        self.file = h5py.File(data_path, 'r')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.modality is Modality.MESH:\n",
    "            features = self.file['features'][index][:].reshape(-1, 15)\n",
    "            neighbors = self.file['neighbors'][index][:].reshape(-1, 3)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                features = self.transform(features)\n",
    "                \n",
    "                \n",
    "            features = torch.from_numpy(features).float()\n",
    "            neighbors = torch.from_numpy(neighbors).long()\n",
    "        \n",
    "            features = torch.permute(features, (1, 0))\n",
    "            centers, corners, normals = features[:3], features[3:12], features[12:]\n",
    "            corners = corners - np.concatenate([centers, centers, centers], 0)\n",
    "            \n",
    "            return centers, corners, normals, neighbors\n",
    "        \n",
    "        elif self.modality is Modality.POINT_CLOUD:\n",
    "            points = self.file['points'][index][:]\n",
    "            face_index = self.file['face_index'][index][:]\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                points = self.transform(points)\n",
    "                \n",
    "            points = torch.from_numpy(points).float()\n",
    "            points = torch.permute(points, (1, 0))\n",
    "            return points, torch.from_numpy(face_index).long()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.file['points'].shape[0]\n",
    "    \n",
    "    \n",
    "class DoubleDataset(CrossmodalDataset):\n",
    "    def __init__(self, **multimodal_dataset_kwargs):\n",
    "        super().__init__(**multimodal_dataset_kwargs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return super().__getitem__(idx), super().__getitem__(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return super().__len__()\n",
    "\n",
    "    \n",
    "class DoubleModalityDataset(Dataset):\n",
    "    def __init__(self, dset1, dset2):\n",
    "        super().__init__()\n",
    "        self.dset1 = dset1\n",
    "        self.dset2 = dset2\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return *self.dset1.__getitem__(idx), *self.dset2.__getitem__(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dset1.__len__()\n",
    "        \n",
    "        \n",
    "        \n",
    "def sample(x, num_points=1024):\n",
    "    device = x.device\n",
    "    B, C, N = x.shape\n",
    "    centroids = torch.zeros(B, num_points, dtype=torch.long, device=device)\n",
    "    distance = torch.ones(B, N, device=device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long, device=device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long, device=device)\n",
    "    for i in range(num_points):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = x[batch_indices, :, farthest].view(B, C, 1)\n",
    "        dist = torch.sum((x - centroid) ** 2, 1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def move_to_device(data, device='cpu'):\n",
    "    if isinstance(data, list):\n",
    "        return [item.to(device) for item in data]\n",
    "    else:\n",
    "        return data.to(device)\n",
    "        \n",
    "        \n",
    "def collate_clouds(data, num_points=1024, device='cpu'):\n",
    "    batch, face_indexes = move_to_device(default_collate(data), device)\n",
    "    \n",
    "    centroids_idx = sample(batch, num_points)\n",
    "    \n",
    "    batch = torch.gather(batch, 2, centroids_idx.unsqueeze(1).expand(-1, batch.size(1), -1))\n",
    "    face_indexes = torch.gather(face_indexes, 1, centroids_idx)\n",
    "    \n",
    "    return batch, face_indexes\n",
    "\n",
    "        \n",
    "def collate_meshes(data, device='cpu'):\n",
    "    max_faces = 0\n",
    "    centers = []\n",
    "    corners = []\n",
    "    normals = []\n",
    "    neighbors = []\n",
    "    for centers_, corners_, normals_, neighbors_ in data:\n",
    "        max_faces = max(max_faces, neighbors_.shape[0])\n",
    "    \n",
    "    for centers_, corners_, normals_, neighbors_ in data:\n",
    "        num_faces = neighbors_.shape[0]\n",
    "        if num_faces < max_faces:\n",
    "            fill_idx = np.random.choice(num_faces, max_faces - num_faces)\n",
    "            centers.append(torch.concat([centers_, centers_[:, fill_idx]], dim=1))\n",
    "            corners.append(torch.concat([corners_, corners_[:, fill_idx]], dim=1))\n",
    "            normals.append(torch.concat([normals_, normals_[:, fill_idx]], dim=1))\n",
    "            neighbors.append(torch.concat([neighbors_, neighbors_[fill_idx]]))\n",
    "        else:\n",
    "            centers.append(centers_)\n",
    "            corners.append(corners_)\n",
    "            normals.append(normals_)\n",
    "            neighbors.append(neighbors_)\n",
    "        \n",
    "    centers = torch.stack(centers).to(device)\n",
    "    corners = torch.stack(corners).to(device)\n",
    "    normals = torch.stack(normals).to(device)\n",
    "    neighbors = torch.stack(neighbors).to(device)\n",
    "    \n",
    "    return centers, corners, normals, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "with h5py.File('abc_train.hdf5') as h5r:\n",
    "    pc_batch = [\n",
    "        (h5r['points'][index][:].T, h5r['face_index'][index][:]),\n",
    "        (h5r['points'][index + 1][:].T, h5r['face_index'][index + 1][:]),\n",
    "        (h5r['points'][index + 2][:].T, h5r['face_index'][index + 2][:]),\n",
    "        (h5r['points'][index + 3][:].T, h5r['face_index'][index + 3][:]),\n",
    "        (h5r['points'][index + 4][:].T, h5r['face_index'][index + 4][:]),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby(features, face_indexes, max_faces):\n",
    "    '''\n",
    "    :param features: features for all face/point/pixel/voxel, batch_size x feature_dim x n_features\n",
    "    :param labels: patches/segmentation labels, batch_size x n_features\n",
    "    '''    \n",
    "    mask = face_indexes.unsqueeze(1) == torch.arange(max_faces).unsqueeze(1).to(face_indexes.device)\n",
    "    zero = torch.FloatTensor([0]).to(face_indexes.device)\n",
    "    grouped = torch.where(mask.unsqueeze(2), features.unsqueeze(1), zero)\n",
    "    \n",
    "    return grouped, mask\n",
    "\n",
    "\n",
    "def get_patch_embeddings(features, labels, max_faces):\n",
    "    \"\"\"\n",
    "    :param features: features for all face/point/pixel/voxel, batch_size x feature_dim x n_features\n",
    "    :param labels: patches/segmentation labels, batch_size x n_features\n",
    "    :return: pooled (BxFxN), counts (BxN)\n",
    "    \"\"\"\n",
    "    grouped, mask = groupby(features, labels, max_faces)\n",
    "    counts = mask.sum(axis=-1)\n",
    "    counts_nonzero = torch.where(counts != 0, counts, 1)\n",
    "\n",
    "    pooled = grouped.sum(dim=-1) / counts_nonzero.unsqueeze(2)\n",
    "\n",
    "    return pooled.transpose(1, 2), counts\n",
    "\n",
    "\n",
    "def face_indexes_to_patch_counts(face_indexes, max_faces):\n",
    "    face_nums = face_indexes.max(1).values\n",
    "    idx = torch.arange(max_faces).unsqueeze(0)\\\n",
    "          .expand(face_indexes.size(0), -1).to(face_indexes.device)\n",
    "    return (idx < face_nums.unsqueeze(1)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def patch_contrastive_loss(x1, x2, params):\n",
    "    \"\"\"\n",
    "    x1 and x2 are tuples with not flattened embeddings and patch_counts\n",
    "    \"\"\"\n",
    "    v1_embeddings, v1_patch_counts = x1\n",
    "    v2_embeddings, v2_patch_counts = x2\n",
    "\n",
    "    n_patches = v1_embeddings.size(2)\n",
    "\n",
    "    v1_embeddings = F.normalize(v1_embeddings, dim=1)\n",
    "    v2_embeddings = F.normalize(v2_embeddings, dim=1)\n",
    "\n",
    "    embs = torch.cat((v1_embeddings, v2_embeddings), dim=2)\n",
    "    # b x (2 * n_patches) x (2 * n_patches)\n",
    "    logits = torch.bmm(embs.transpose(2, 1), embs) / params['tau']\n",
    "\n",
    "    # discard self similarities\n",
    "    mask = ~torch.eye(n_patches * 2, dtype=torch.bool, device=v1_embeddings.device)\n",
    "    logits = (logits\n",
    "              .masked_select(mask)\n",
    "              .view(-1, 2 * n_patches, 2 * n_patches - 1)\n",
    "              .transpose(2, 1)\n",
    "              .contiguous()\n",
    "              )\n",
    "\n",
    "    # ignore error for empty patches\n",
    "    empty_patches_mask = torch.cat(((v1_patch_counts == 0), (v2_patch_counts == 0)), dim=1)\n",
    "    labels = torch.cat((torch.arange(n_patches) + n_patches - 1,\n",
    "                        torch.arange(n_patches)\n",
    "                        ), dim=0).to(v1_embeddings.device)\n",
    "    ignore_label = torch.Tensor([-100]).to(v1_embeddings.device).long()\n",
    "    labels = torch.where(empty_patches_mask, ignore_label, labels)\n",
    "\n",
    "    return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658fb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicollate(data, *collators):\n",
    "    batches = [[] for i in range(len(collators))]\n",
    "    for item in data:\n",
    "        for i in range(len(collators)):\n",
    "            batches[i].append(item[i])\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i, collator in enumerate(collators):\n",
    "        result.append(collator(batches[i]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate = lambda data: multicollate(\n",
    "    data,\n",
    "    lambda x: collate_meshes(x, device=device),\n",
    "    lambda x: collate_meshes(x, device=device),\n",
    "    lambda x: collate_clouds(x, device=device),\n",
    "    lambda x: collate_clouds(x, device=device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67197cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace.datasets.transforms import *\n",
    "\n",
    "pdataset_train = DoubleDataset(data_path='abc_train.hdf5', modality=Modality.POINT_CLOUD,\n",
    "                            transform=Compose(\n",
    "        PointCloudNormalize(),\n",
    "        RandomRotation(low=-45, high=45, axis='xyz'),\n",
    "        RandomJitter(std=0.01, clip_bound=0.05)\n",
    "    ),)\n",
    "mdataset_train = DoubleDataset(data_path='abc_train.hdf5', modality=Modality.MESH,\n",
    "                            transform=Compose(\n",
    "        MeshNetRandomRotation(low=-45, high=45, axis='xyz'),\n",
    "        MeshNetRandomJitter(std=0.01, clip_bound=0.05)\n",
    "    ),)\n",
    "\n",
    "train = DoubleModalityDataset(mdataset_train, pdataset_train)\n",
    "\n",
    "\n",
    "pdataset_test = DoubleDataset(data_path='abc_test.hdf5', modality=Modality.POINT_CLOUD,\n",
    "                            transform=Compose(\n",
    "        PointCloudNormalize(),\n",
    "        RandomRotation(low=-45, high=45, axis='xyz'),\n",
    "        RandomJitter(std=0.01, clip_bound=0.05)\n",
    "    ),)\n",
    "mdataset_test = DoubleDataset(data_path='abc_test.hdf5', modality=Modality.MESH,\n",
    "                             transform=Compose(\n",
    "        MeshNetRandomRotation(low=-45, high=45, axis='xyz'),\n",
    "        MeshNetRandomJitter(std=0.01, clip_bound=0.05)\n",
    "    ),)\n",
    "\n",
    "test = DoubleModalityDataset(mdataset_test, pdataset_test)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=6, shuffle=False,\n",
    "               collate_fn=collate\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test, batch_size=6, shuffle=False,\n",
    "              collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c096f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# def contrastive_loss(v1_emb, v2_emb, params):\n",
    "#     device = v1_emb.device\n",
    "#     v1_emb = F.normalize(v1_emb, dim=-1)\n",
    "#     v2_emb = F.normalize(v2_emb, dim=-1)\n",
    "    \n",
    "#     v1_logits = v1_emb @ v2_emb.T / params['tau']\n",
    "#     v2_logits = v2_emb @ v1_emb.T / params['tau']\n",
    "    \n",
    "#     labels = torch.arange(v1_emb.shape[0]).to(device)\n",
    "    \n",
    "#     loss1 = F.cross_entropy(v1_logits, labels)\n",
    "#     loss2 = F.cross_entropy(v2_logits, labels)\n",
    "    \n",
    "#     return loss1 + loss2\n",
    "\n",
    "def contrastive_loss(v1_embeddings, v2_embeddings, params):\n",
    "    v1_embeddings = F.normalize(v1_embeddings, dim=1)\n",
    "    v2_embeddings = F.normalize(v2_embeddings, dim=1)\n",
    "\n",
    "    batch_size = v1_embeddings.size(0)\n",
    "    embs = torch.cat((v1_embeddings, v2_embeddings), dim=0)\n",
    "    logits = embs @ embs.transpose(1, 0) / params['tau']\n",
    "\n",
    "    # discard self similarities\n",
    "    mask = ~torch.eye(2 * batch_size, dtype=torch.bool, device=v1_embeddings.device)\n",
    "    logits = (logits\n",
    "              .masked_select(mask)\n",
    "              .view(2 * batch_size, 2 * batch_size - 1)\n",
    "              .contiguous()\n",
    "              )\n",
    "\n",
    "    labels = torch.cat((torch.arange(batch_size) + batch_size - 1,\n",
    "                        torch.arange(batch_size)\n",
    "                        ), dim=0).to(v1_embeddings.device)\n",
    "\n",
    "    return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02551b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(torch.nn.Module):\n",
    "    def __init__(self, *dims):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, data):\n",
    "        return data.transpose(*self.dims)\n",
    "    \n",
    "\n",
    "class MultiModalModel(torch.nn.Module):\n",
    "    def __init__(self, model1, model2, model_output_dim, result_dim=64, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.model1 = model1.to(device1)\n",
    "        self.model2 = model2.to(device2)\n",
    "        self.head1 = torch.nn.Sequential(\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(model_output_dim, hidden_dim),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(hidden_dim, result_dim),\n",
    "            Transpose(1, 2),\n",
    "        ).to(device1)\n",
    "        \n",
    "        self.head2 = torch.nn.Sequential(\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(model_output_dim, hidden_dim),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(hidden_dim, result_dim),\n",
    "            Transpose(1, 2),\n",
    "        ).to(device2)\n",
    "        \n",
    "        \n",
    "    def forward(self, input1_1, input1_2, input2_1, input2_2):\n",
    "        v1_1_emb = self.model1.forward_features(input1_1)\n",
    "        v1_2_emb = self.model1.forward_features(input1_2)\n",
    "        \n",
    "        input2_1, face_indexes = input2_1\n",
    "        input2_2, face_indexes = input2_2\n",
    "        v2_1_emb = self.model2.forward_features(input2_1)\n",
    "        v2_2_emb = self.model2.forward_features(input2_2)\n",
    "        \n",
    "        \n",
    "        return (\n",
    "            self.head1(v1_1_emb),\n",
    "            self.head1(v1_2_emb),\n",
    "            self.head2(v2_1_emb),\n",
    "            self.head2(v2_2_emb),\n",
    "            face_indexes\n",
    "        )\n",
    "    \n",
    "\n",
    "    def get_embeddings(self, input1_1, input1_2, input2_1, input2_2):\n",
    "        v1_1_emb = self.model1.forward_features(input1_1)\n",
    "        v1_2_emb = self.model1.forward_features(input1_2)\n",
    "        v2_1_emb = self.model2.forward_features(input2_1)\n",
    "        v2_2_emb = self.model2.forward_features(input2_2)\n",
    "        \n",
    "        return v1_1_emb, v1_2_emb, v2_1_emb, v2_2_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace.models.meshnet import MeshNet\n",
    "from workspace.models.dgcnn import DGCNN\n",
    "\n",
    "mnet = MeshNet(n_patches=5)\n",
    "dgcnn = DGCNN(n_patches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiModalModel(mnet, dgcnn, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62044e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_patch_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d38bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_patches_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def forward( \n",
    "    model,\n",
    "    batch, # raw data from dataloader\n",
    "    logger, # neptune run\n",
    "    mode # 'train'/'val'\n",
    "): # -> loss\n",
    "\n",
    "    data1_1, data1_2, data2_1, data2_2 = batch\n",
    "    \n",
    "    max_faces = data1_1[0].shape[-1]\n",
    "    global last_batch\n",
    "    last_batch = deepcopy(batch)\n",
    "\n",
    "    out1_1, out1_2, out2_1, out2_2, face_indexes = model(data1_1, data1_2, data2_1, data2_2)\n",
    "    \n",
    "    pooled2_1, counts2_1 = get_patch_embeddings(out2_1, face_indexes, max_faces)\n",
    "    pooled2_2, counts2_2 = get_patch_embeddings(out2_2, face_indexes, max_faces)\n",
    "    face_counts = face_indexes_to_patch_counts(face_indexes, max_faces)\n",
    "    \n",
    "    #local inside figures\n",
    "    pc_local_loss = patch_contrastive_loss(\n",
    "        (pooled2_1, counts2_1),\n",
    "        (pooled2_2, counts2_2),\n",
    "        params\n",
    "    )\n",
    "    mesh_local_loss = patch_contrastive_loss(\n",
    "        (out1_1, face_counts),\n",
    "        (out1_2, face_counts),\n",
    "        params\n",
    "    )\n",
    "    \n",
    "    #local crossmodal loss\n",
    "    local_crossmodal_loss = (\n",
    "        patch_contrastive_loss(\n",
    "            (pooled2_1, counts2_1),\n",
    "            (out1_1, face_counts),\n",
    "            params\n",
    "        ) + \n",
    "        patch_contrastive_loss(\n",
    "            (pooled2_1, counts2_1),\n",
    "            (out1_2, face_counts),\n",
    "            params\n",
    "        ) +\n",
    "        patch_contrastive_loss(\n",
    "            (pooled2_2, counts2_2),\n",
    "            (out1_1, face_counts),\n",
    "            params\n",
    "        ) + \n",
    "        patch_contrastive_loss(\n",
    "            (pooled2_2, counts2_2),\n",
    "            (out1_2, face_counts),\n",
    "            params\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    gout1_1 = out1_1.mean(-1)\n",
    "    gout1_2 = out1_2.mean(-1)\n",
    "    gout2_1 = out2_1.mean(-1)\n",
    "    gout2_2 = out2_2.mean(-1)\n",
    "    # crossmodal\n",
    "    crossmodal_loss = contrastive_loss(gout1_1, gout2_1, params) +\\\n",
    "           contrastive_loss(gout1_2, gout2_2, params) +\\\n",
    "           contrastive_loss(gout1_1, gout2_2, params) +\\\n",
    "           contrastive_loss(gout1_2, gout2_1, params)\n",
    "    \n",
    "    # model level\n",
    "    pc_loss = contrastive_loss(gout1_1, gout1_2, params)\n",
    "    mesh_loss = contrastive_loss(gout2_1, gout2_2, params)\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'loss': (0.25 * crossmodal_loss + pc_loss + mesh_loss) +\\\n",
    "                (0.25 * local_crossmodal_loss + pc_local_loss + mesh_local_loss),\n",
    "        'pc_loss': pc_loss,\n",
    "        'pc_local_loss': pc_local_loss,\n",
    "        'mesh_local_loss': mesh_local_loss,\n",
    "        'mesh_loss': mesh_loss,\n",
    "        'local_crossmodal_loss': 0.25 * local_crossmodal_loss,\n",
    "        'crossmodal_loss:': 0.25 * crossmodal_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387e1ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "from workspace.utils.train_loop import *\n",
    "\n",
    "params = {\n",
    "    'name': 'Experiment_multimodal_abc',\n",
    "    'dataset': 'abc',\n",
    "    'batch_size': 8,\n",
    "    'tau': 0.07,\n",
    "    'n_output': 512,\n",
    "    'total_epochs': 100,\n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 1e-5,\n",
    "    'save_every': 100,\n",
    "    'weights_root': '../weights/'\n",
    "}\n",
    "\n",
    "# tags\n",
    "tags = ['abc']\n",
    "\n",
    "\n",
    "\n",
    "logger = neptune.init(project='seals5454/crossmodal-exps-igor',\n",
    "                      name=params['name'],\n",
    "                      tags=tags,\n",
    "                      api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmU'\\\n",
    "                                'uYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS'\\\n",
    "                                '5haSIsImFwaV9rZXkiOiI2NTIwODVkNC1hOTg5LTQ4NTAtY'\\\n",
    "                                'WRhNS0yMGY4MmQ1YzBmZWIifQ=='\n",
    "                      )\n",
    "\n",
    "logger['parameters'] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=params['lr'],\n",
    "    weight_decay=params['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * params['total_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f155bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, params, logger,  train_loader, test_loader, optimizer, scheduler, forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3971a",
   "metadata": {},
   "source": [
    "## ВИЗУАЛИЗАЦИЯ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from workspace.datasets.transforms import *\n",
    "\n",
    "\n",
    "\n",
    "def visualize_elements_heatmap_pc(point_cloud, features, anchor_idx=-1):\n",
    "    '''\n",
    "    :param point_cloud: point cloud, tensor of size (n_points, 3)\n",
    "    :param features: point cloud features, tensor of size (n_points, emb_dim)\n",
    "    '''\n",
    "    if anchor_idx == -1:\n",
    "        anchor_idx = np.random.randint(0, point_cloud.size(0), size=(1,))[0]\n",
    "        \n",
    "    features = F.normalize(features, dim=-1)\n",
    "                \n",
    "    sims = features[anchor_idx] @ features.t()\n",
    "    plot = k3d.plot()\n",
    "    plot += k3d.points(point_cloud, point_size=0.025, attribute=sims)\n",
    "    plot += k3d.points(point_cloud[anchor_idx].unsqueeze(0), point_size=0.05)\n",
    "\n",
    "    return plot\n",
    "\n",
    "\n",
    "def visualize_elements_heatmap_mesh(mesh, features, anchor_idx=-1):\n",
    "    '''\n",
    "    :param mesh: tuple (vertices, faces)\n",
    "    :param features: faces features, tensor of size (>=n_faces, emb_dim)\n",
    "    '''\n",
    "    vertices, faces = mesh\n",
    "    vertices = PointCloudNormalize()(vertices)\n",
    "    faces_num = faces.shape[0]\n",
    "    features = features[:faces_num]\n",
    "    \n",
    "    if anchor_idx == -1:\n",
    "        anchor_idx = np.random.randint(0, faces_num, size=(1,))[0]\n",
    "        \n",
    "    features = F.normalize(features, dim=-1)\n",
    "    sims = features[anchor_idx] @ features.t()\n",
    "    plot = k3d.plot()\n",
    "    \n",
    "    anchor_face = faces[anchor_idx]\n",
    "    anchor_point = (vertices[anchor_face[0]] +\n",
    "                    vertices[anchor_face[1]] +\n",
    "                    vertices[anchor_face[2]]) / 3\n",
    "    plot += k3d.mesh(vertices, faces, triangles_attribute=sims[:faces.shape[0]])\n",
    "    plot += k3d.points(anchor_point[None, ...], point_size=0.1, color=0xff0000)\n",
    "    \n",
    "    return plot\n",
    "\n",
    "\n",
    "def visualize_elements_heatmap_pc_to_mesh(point_cloud, mesh, features_pc, features_mesh, anchor_idx=-1):\n",
    "    '''\n",
    "    :param point_cloud: point cloud, tensor of size (n_points, 3)\n",
    "    :param mesh: tuple (vertices, faces)\n",
    "    :param features_pc: point cloud features, tensor of size (n_points, emb_dim)\n",
    "    :param features_mesh: faces features, tensor of size (>=n_faces, emb_dim)\n",
    "    '''\n",
    "    vertices, faces = mesh\n",
    "    faces_num = faces.shape[0]\n",
    "    features_mesh = features_mesh[:faces_num]\n",
    "    features_mesh = F.normalize(features_mesh, dim=-1)\n",
    "    features_pc = F.normalize(features_pc, dim=-1)\n",
    "    \n",
    "    \n",
    "    if anchor_idx == -1:\n",
    "        anchor_idx = np.random.randint(0, point_cloud.size(0), size=(1,))[0]\n",
    "        \n",
    "    sims_pc = features_pc[anchor_idx] @ features_pc.T\n",
    "    sims_mesh = features_pc[anchor_idx] @ features_mesh.T\n",
    "    plot = k3d.plot()\n",
    "    vertices = PointCloudNormalize()(vertices)\n",
    "    vertices[:, 0] += 2\n",
    "    \n",
    "    plot += k3d.mesh(vertices, faces, triangles_attribute=sims_mesh)\n",
    "    plot += k3d.points(point_cloud, point_size=0.025, attribute=sims_pc)\n",
    "    plot += k3d.points(point_cloud[anchor_idx].unsqueeze(0), point_size=0.1, color=0xff0000)\n",
    "\n",
    "    return plot\n",
    "\n",
    "\n",
    "def visualize_elements_heatmap_mesh_to_pc(point_cloud, mesh, features_pc, features_mesh, anchor_idx=-1):\n",
    "    '''\n",
    "    :param point_cloud: point cloud, tensor of size (n_points, 3)\n",
    "    :param mesh: tuple (vertices, faces)\n",
    "    :param features_pc: point cloud features, tensor of size (n_points, emb_dim)\n",
    "    :param features_mesh: faces features, tensor of size (>=n_faces, emb_dim)\n",
    "    '''\n",
    "    vertices, faces = mesh\n",
    "    faces_num = faces.shape[0]\n",
    "    features_mesh = features_mesh[:faces_num]\n",
    "    features_mesh = F.normalize(features_mesh, dim=-1)\n",
    "    features_pc = F.normalize(features_pc, dim=-1)\n",
    "    \n",
    "    \n",
    "    if anchor_idx == -1:\n",
    "        anchor_idx = np.random.randint(0, faces_num, size=(1,))[0]\n",
    "        \n",
    "    sims_pc = features_mesh[anchor_idx] @ features_pc.T\n",
    "    sims_mesh = features_mesh[anchor_idx] @ features_mesh.T\n",
    "    plot = k3d.plot()\n",
    "    vertices = PointCloudNormalize()(vertices)\n",
    "    vertices[:, 0] += 2\n",
    "    \n",
    "    anchor_face = faces[anchor_idx]\n",
    "    anchor_point = (vertices[anchor_face[0]] +\n",
    "                    vertices[anchor_face[1]] +\n",
    "                    vertices[anchor_face[2]]) / 3\n",
    "    \n",
    "    plot += k3d.mesh(vertices, faces, triangles_attribute=sims_mesh)\n",
    "    plot += k3d.points(point_cloud, point_size=0.025, attribute=sims_pc)\n",
    "    plot += k3d.points(anchor_point[None, ...], point_size=0.1, color=0xff0000)\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ffe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('exp41')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddf14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "feats = model(*next(iter(train_loader)))\n",
    "point_cloud = next(iter(train_loader))[3][0][index].T.cpu()\n",
    "pc_features = feats[3][index].T.detach().cpu()\n",
    "m_features = feats[0][index].T.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('abc_train.hdf5', 'r') as h5r:\n",
    "    mesh = h5r['vertices'][index][:].reshape(-1, 3), h5r['faces'][index][:].reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_elements_heatmap_pc_to_mesh(point_cloud, mesh, pc_features, m_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4410327",
   "metadata": {},
   "source": [
    "Активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    activations = model(*batch)\n",
    "    fm1, fm2, fp1, fp2, _ = activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 = F.normalize(fm1.mean(-1).detach().cpu(), dim=-1)\n",
    "fm2 = F.normalize(fm2.mean(-1).detach().cpu(), dim=-1)\n",
    "fp1 = F.normalize(fp1.mean(-1).detach().cpu(), dim=-1)\n",
    "fp2 = F.normalize(fp2.mean(-1).detach().cpu(), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19032466",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 @ fm2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp1 @ fp2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074cc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 @ fp1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490b2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
