{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19266e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "# Path to workspace\n",
    "sys.path.insert(0, '/workspace/dense-self-supervised-representation-learning-for-3D-shapes/')\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355be047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "from workspace.utils.train_loop import *\n",
    "\n",
    "params = {\n",
    "    'name': 'modelnet_cls_linprobe',\n",
    "    'dataset': 'modelnet',\n",
    "    'batch_size': 15,\n",
    "    'tau': 0.07,\n",
    "    'n_output': 512,\n",
    "    'result_dim': 3,\n",
    "    'hidden_dim': 256,\n",
    "    'total_epochs': 100,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-5,\n",
    "    'save_every': 50,\n",
    "    'weights_root': 'weights/'\n",
    "}\n",
    "\n",
    "# tags\n",
    "# tags = ['modelnet', 'classification', 'linprobe']\n",
    "\n",
    "# logger = neptune.init(\n",
    "#     project=\"igor3661/crossmodal\",\n",
    "#     name=params['name'],\n",
    "#     tags=tags,\n",
    "#     api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcG'\\\n",
    "#               'lfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiN'\\\n",
    "#               'zcxMGNkOS04ZjU3LTRmNDMtOWFjMS1kNDNkZDZlNDI4YWYifQ==',\n",
    "# )  # your credentials\n",
    "\n",
    "\n",
    "# logger['parameters'] = params\n",
    "\n",
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb0ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from workspace.crossmodal.utils.meshnet_preprop import *\n",
    "\n",
    "\n",
    "class PointDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.file = h5py.File(data_path, 'r')\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        points = self.file['points'][index][:]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            points = self.transform(points)\n",
    "\n",
    "        points = torch.from_numpy(points).float()\n",
    "        points = torch.permute(points, (1, 0))\n",
    "        return points\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.file['points'].shape[0]\n",
    "    \n",
    "class MeshnetDataset(Dataset):\n",
    "    def __init__(self, data_path, rotation=None, jitter=None):\n",
    "        super().__init__()\n",
    "        self.rotation = rotation\n",
    "        self.jitter = jitter\n",
    "        self.file = h5py.File(data_path, 'r')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        faces = self.file['faces'][index][:].reshape(-1, 3)\n",
    "        vertices = self.file['vertices'][index][:].reshape(-1, 3)\n",
    "        \n",
    "        if self.rotation is not None:\n",
    "            vertices = self.rotation(vertices)\n",
    "        \n",
    "        features, neighbors = process_mesh(faces, vertices)\n",
    "        \n",
    "\n",
    "        features = torch.from_numpy(features).float()\n",
    "        neighbors = torch.from_numpy(neighbors).long()\n",
    "\n",
    "        features = torch.permute(features, (1, 0))\n",
    "        centers, corners, normals = features[:3], features[3:12], features[12:]\n",
    "        \n",
    "        if self.jitter is not None:\n",
    "            centers = self.jitter(centers).float()\n",
    "        \n",
    "        corners = corners - torch.cat([centers, centers, centers], 0).float()\n",
    "\n",
    "        return centers, corners, normals, neighbors\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.file['points'].shape[0]\n",
    "    \n",
    "\n",
    "class DoubleDataset(Dataset):\n",
    "    def __init__(self, kwargs):\n",
    "        super().__init__()\n",
    "        self.mesh = MeshnetDataset(**kwargs['mesh'])\n",
    "        self.point = PointDataset(**kwargs['point'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.mesh.file['labels'][idx]\n",
    "        face_index = torch.from_numpy(self.mesh.file['face_index'][idx][:]).long()\n",
    "        return (*self.mesh.__getitem__(idx), self.point.__getitem__(idx), label, face_index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mesh.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba045bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {\n",
    "    'mesh': {\n",
    "        'data_path': 'modelnet/modelnet_train_1024.h5',\n",
    "    },\n",
    "    'point': {\n",
    "        'data_path': 'modelnet/modelnet_train_1024.h5',\n",
    "    }\n",
    "}\n",
    "\n",
    "test_kwargs = {\n",
    "    'mesh': {\n",
    "        'data_path': 'modelnet/modelnet_test_1024.h5',\n",
    "    },\n",
    "    'point': {\n",
    "        'data_path': 'modelnet/modelnet_test_1024.h5',\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "train_data = DoubleDataset(train_kwargs)\n",
    "test_data = DoubleDataset(test_kwargs)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=params['batch_size'],\n",
    "    num_workers=10,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=params['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7afd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(torch.nn.Module):\n",
    "    def __init__(self, *dims):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, data):\n",
    "        return data.transpose(*self.dims)\n",
    "    \n",
    "\n",
    "class NormalsModel(torch.nn.Module):\n",
    "    def __init__(self, model, model_output_dim, result_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.head = torch.nn.Sequential(\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(model_output_dim, hidden_dim),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(hidden_dim, 128),\n",
    "            Transpose(1, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.head(self.model.forward_features(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231a825e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from workspace.models.dgcnn import DGCNN\n",
    "from workspace.models.meshnet import MeshNet\n",
    "\n",
    "meshnet = MeshNet(n_patches=5)\n",
    "dgcnn = DGCNN(n_patches=5)\n",
    "\n",
    "mesh_model = NormalsModel(\n",
    "    meshnet,\n",
    "    model_output_dim=params['n_output'],\n",
    "    hidden_dim=params['hidden_dim'],\n",
    "    result_dim=params['result_dim']\n",
    ").to(device).eval()\n",
    "# point_model = NormalsModel(\n",
    "#     dgcnn,\n",
    "#     model_output_dim=params['n_output'],\n",
    "#     hidden_dim=params['hidden_dim'],\n",
    "#     result_dim=params['result_dim']\n",
    "# ).to(device).eval()\n",
    "\n",
    "mesh_model.load_state_dict(torch.load('weights/CROSS-57/100epoch.pt'))\n",
    "# point_model.load_state_dict(torch.load('weights/CROSS-56/100epoch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb14b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Projector(torch.nn.Module):\n",
    "    def __init__(self, model_output_dim):\n",
    "        super().__init__()\n",
    "        self.head = torch.nn.Sequential(\n",
    "                #Transpose(1, 2),\n",
    "                torch.nn.Linear(model_output_dim, model_output_dim * 2),\n",
    "                #Transpose(1, 2),\n",
    "                torch.nn.BatchNorm1d(model_output_dim * 2),\n",
    "                torch.nn.ReLU(),\n",
    "                #Transpose(1, 2),\n",
    "                torch.nn.Linear(model_output_dim * 2, model_output_dim),\n",
    "                #Transpose(1, 2),\n",
    "            )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        return self.head(data)\n",
    "\n",
    "proj = Projector(params['n_output']).to(device).eval()\n",
    "proj.load_state_dict(torch.load('weights/CROSS-79/100epoch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2689ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def move_to_device(data, device='cpu'):\n",
    "    if isinstance(data, list):\n",
    "        return [item.to(device) for item in data]\n",
    "    else:\n",
    "        return data.to(device)\n",
    "    \n",
    "    \n",
    "def collect_embeddings(loader):\n",
    "    all_embeddings = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for centers, corners, normals, neighbors, points, labels, face_index in tqdm(loader):\n",
    "        mesh_data = move_to_device([centers, corners, normals, neighbors], device)\n",
    "        points = points.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        point_embs = point_model.model.forward_features(points).detach().cpu().mean(-1)\n",
    "        mesh_embs = mesh_model.model.forward_features(mesh_data).detach()\n",
    "        \n",
    "        projected = proj(mesh_embs).detach().cpu()\n",
    "        gathered = torch.gather(projected, 2, face_index.unsqueeze(1).expand((-1, 512, -1))).mean(-1)\n",
    "        \n",
    "        \n",
    "        all_embeddings.append(gathered)\n",
    "        all_targets.append(labels.cpu())\n",
    "        \n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "        \n",
    "    return all_embeddings, all_targets\n",
    "\n",
    "def collect_embeddings_coords(loader):\n",
    "    all_embeddings = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for centers, corners, normals, neighbors, points, labels, face_index in tqdm(loader):\n",
    "        mesh_data = move_to_device([centers, corners, normals, neighbors], device)\n",
    "        centers = mesh_data[0]\n",
    "        points = points.to(device)\n",
    "        labels = labels.to(device)\n",
    "        face_index = face_index.to(device)\n",
    "        \n",
    "        #point_embs = point_model.model.forward_features(points).detach().cpu().mean(-1)\n",
    "        mesh_embs = mesh_model.model.forward_features(mesh_data).detach()\n",
    "        \n",
    "        #concated = torch.cat([mesh_embs, centers], dim=1)\n",
    "        \n",
    "        gathered = torch.gather(mesh_embs, 2, face_index.unsqueeze(1).expand((-1, 512, -1)))\n",
    "        concated = torch.cat([gathered, points], dim=1)\n",
    "\n",
    "        projected = proj(concated).detach().cpu().mean(-1)\n",
    "        \n",
    "        all_embeddings.append(projected)\n",
    "        all_targets.append(labels.cpu())\n",
    "        \n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "        \n",
    "    return all_embeddings, all_targets\n",
    "\n",
    "def collect_embeddings_global(loader):\n",
    "    all_embeddings = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for centers, corners, normals, neighbors, points, labels, face_index in tqdm(loader):\n",
    "        mesh_data = move_to_device([centers, corners, normals, neighbors], device)\n",
    "        centers = mesh_data[0]\n",
    "        points = points.to(device)\n",
    "        labels = labels.to(device)\n",
    "        face_index = face_index.to(device)\n",
    "        \n",
    "        #point_embs = point_model.model.forward_features(points).detach().cpu().mean(-1)\n",
    "        mesh_embs = mesh_model.model.forward_features(mesh_data).detach().mean(-1)\n",
    "\n",
    "        projected = proj(mesh_embs).detach().cpu()\n",
    "        \n",
    "        all_embeddings.append(projected)\n",
    "        all_targets.append(labels.cpu())\n",
    "        \n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "        \n",
    "    return all_embeddings, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea23f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:08<00:00, 20.39it/s]\n",
      "100%|██████████| 657/657 [00:26<00:00, 24.68it/s]\n"
     ]
    }
   ],
   "source": [
    "test_embeddings, test_labels = collect_embeddings_global(test_loader)\n",
    "train_embeddings, train_labels = collect_embeddings_global(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7ad3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_svm(X, y):\n",
    "    svm = SVC(kernel='linear')\n",
    "    perm = np.random.permutation(X.shape[0])\n",
    "    svm.fit(X[perm], y[perm])\n",
    "    return svm\n",
    "\n",
    "\n",
    "def train_eval(X_train, y_train, X_test, y_test):\n",
    "    print('X_train size:', X_train.shape[0], 'X_test size:', X_test.shape[0], 'dim:', X_train.shape[1])\n",
    "    svm = train_svm(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94848050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 9842 X_test size: 2468 dim: 512\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = train_eval(train_embeddings, train_labels, test_embeddings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94889324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8761    0.9900    0.9296       100\n",
      "           1     0.3333    0.0800    0.1290        50\n",
      "           2     0.3433    0.4600    0.3932       100\n",
      "           3     0.3529    0.3000    0.3243        20\n",
      "           4     0.3690    0.6900    0.4808       100\n",
      "           5     0.8810    0.7400    0.8043       100\n",
      "           6     0.8000    0.4000    0.5333        20\n",
      "           7     0.7407    0.6000    0.6630       100\n",
      "           8     0.4709    0.8100    0.5956       100\n",
      "           9     0.8500    0.8500    0.8500        20\n",
      "          10     0.6250    0.2500    0.3571        20\n",
      "          11     0.3500    0.3500    0.3500        20\n",
      "          12     0.3030    0.1163    0.1681        86\n",
      "          13     0.3600    0.4500    0.4000        20\n",
      "          14     0.4815    0.4535    0.4671        86\n",
      "          15     0.0000    0.0000    0.0000        20\n",
      "          16     0.7670    0.7900    0.7783       100\n",
      "          17     0.9579    0.9100    0.9333       100\n",
      "          18     0.7500    0.7500    0.7500        20\n",
      "          19     0.4286    0.3000    0.3529        20\n",
      "          20     0.6667    0.6000    0.6316        20\n",
      "          21     0.3776    0.3700    0.3737       100\n",
      "          22     0.4786    0.5600    0.5161       100\n",
      "          23     0.5273    0.3372    0.4113        86\n",
      "          24     0.7059    0.6000    0.6486        20\n",
      "          25     0.5132    0.3900    0.4432       100\n",
      "          26     0.8000    0.7600    0.7795       100\n",
      "          27     0.2000    0.1000    0.1333        20\n",
      "          28     1.0000    0.1200    0.2143       100\n",
      "          29     0.1000    0.0500    0.0667        20\n",
      "          30     0.2529    0.6500    0.3641       100\n",
      "          31     0.0000    0.0000    0.0000        20\n",
      "          32     0.6667    0.1000    0.1739        20\n",
      "          33     0.5812    0.6800    0.6267       100\n",
      "          34     0.1714    0.3000    0.2182        20\n",
      "          35     0.6579    0.7500    0.7009       100\n",
      "          36     0.2895    0.1100    0.1594       100\n",
      "          37     0.5420    0.7100    0.6147       100\n",
      "          38     0.2857    0.1000    0.1481        20\n",
      "          39     0.4375    0.3500    0.3889        20\n",
      "\n",
      "    accuracy                         0.5300      2468\n",
      "   macro avg     0.5074    0.4482    0.4468      2468\n",
      "weighted avg     0.5569    0.5300    0.5106      2468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d633c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
