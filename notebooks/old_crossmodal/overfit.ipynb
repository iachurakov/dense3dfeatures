{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "# Path to workspace\n",
    "sys.path.insert(0, '/workspace/3d-shapes-embeddings/contrib/sharp_features/')\n",
    "sys.path.insert(0, '/workspace/dense-self-supervised-representation-learning-for-3D-shapes/')\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, default_collate, DataLoader\n",
    "from enum import Enum\n",
    "\n",
    "class Modality(Enum):\n",
    "    MESH = 'mesh'\n",
    "    POINT_CLOUD = 'point_cloud'\n",
    "    DEPTH_IMG = 'depth_images'\n",
    "    SDF = 'sdf'\n",
    "\n",
    "\n",
    "class CrossmodalDataset(Dataset):\n",
    "    def __init__(self, data_path, modality, transform=None):\n",
    "        super().__init__()\n",
    "        self.modality = modality\n",
    "        self.transform = transform\n",
    "        self.file = h5py.File(data_path, 'r')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.modality is Modality.MESH:\n",
    "            features = self.file['features'][index][:].reshape(-1, 15)\n",
    "            neighbors = self.file['neighbors'][index][:].reshape(-1, 3)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                features = self.transform(features)\n",
    "                \n",
    "                \n",
    "            features = torch.from_numpy(features).float()\n",
    "            neighbors = torch.from_numpy(neighbors).long()\n",
    "        \n",
    "            features = torch.permute(features, (1, 0))\n",
    "            centers, corners, normals = features[:3], features[3:12], features[12:]\n",
    "            corners = corners - np.concatenate([centers, centers, centers], 0)\n",
    "            \n",
    "            return centers, corners, normals, neighbors\n",
    "        \n",
    "        elif self.modality is Modality.POINT_CLOUD:\n",
    "            points = self.file['points'][index][:]\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                points = self.transform(points)\n",
    "                \n",
    "            points = torch.from_numpy(points).float()\n",
    "            points = torch.permute(points, (1, 0))\n",
    "            return points\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.file['points'].shape[0]\n",
    "    \n",
    "    \n",
    "class DoubleDataset(CrossmodalDataset):\n",
    "    def __init__(self, **multimodal_dataset_kwargs):\n",
    "        super().__init__(**multimodal_dataset_kwargs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return super().__getitem__(idx), super().__getitem__(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return super().__len__()\n",
    "\n",
    "    \n",
    "class DoubleModalityDataset(Dataset):\n",
    "    def __init__(self, dset1, dset2):\n",
    "        super().__init__()\n",
    "        self.dset1 = dset1\n",
    "        self.dset2 = dset2\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return *self.dset1.__getitem__(idx), *self.dset2.__getitem__(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 2 #!!!!!!!!!!!!!!!!!!!!!!!!! CHANGE\n",
    "        \n",
    "        \n",
    "        \n",
    "def sample(x, num_points=1024):\n",
    "    device = x.device\n",
    "    B, C, N = x.shape\n",
    "    centroids = torch.zeros(B, num_points, dtype=torch.long, device=device)\n",
    "    distance = torch.ones(B, N, device=device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long, device=device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long, device=device)\n",
    "    for i in range(num_points):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = x[batch_indices, :, farthest].view(B, C, 1)\n",
    "        dist = torch.sum((x - centroid) ** 2, 1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "\n",
    "    return centroids\n",
    "        \n",
    "        \n",
    "def collate_clouds(data, num_points=1024, device='cpu'):\n",
    "    batch = default_collate(data).to(device)\n",
    "    \n",
    "    centroids_idx = sample(batch, num_points)\n",
    "    \n",
    "    batch = torch.gather(batch, 2, centroids_idx.unsqueeze(1).expand(-1, batch.size(1), -1))\n",
    "    \n",
    "    return batch\n",
    "\n",
    "        \n",
    "def collate_meshes(data, device='cpu'):\n",
    "    max_faces = 0\n",
    "    centers = []\n",
    "    corners = []\n",
    "    normals = []\n",
    "    neighbors = []\n",
    "    for centers_, corners_, normals_, neighbors_ in data:\n",
    "        max_faces = max(max_faces, neighbors_.shape[0])\n",
    "    \n",
    "    for centers_, corners_, normals_, neighbors_ in data:\n",
    "        num_faces = neighbors_.shape[0]\n",
    "        if num_faces < max_faces:\n",
    "            fill_idx = np.random.choice(num_faces, max_faces - num_faces)\n",
    "            centers.append(torch.concat([centers_, centers_[:, fill_idx]], dim=1))\n",
    "            corners.append(torch.concat([corners_, corners_[:, fill_idx]], dim=1))\n",
    "            normals.append(torch.concat([normals_, normals_[:, fill_idx]], dim=1))\n",
    "            neighbors.append(torch.concat([neighbors_, neighbors_[fill_idx]]))\n",
    "        else:\n",
    "            centers.append(centers_)\n",
    "            corners.append(corners_)\n",
    "            normals.append(normals_)\n",
    "            neighbors.append(neighbors_)\n",
    "        \n",
    "    centers = torch.stack(centers).to(device)\n",
    "    corners = torch.stack(corners).to(device)\n",
    "    normals = torch.stack(normals).to(device)\n",
    "    neighbors = torch.stack(neighbors).to(device)\n",
    "    \n",
    "    return centers, corners, normals, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ac1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicollate(data, *collators):\n",
    "    batches = [[] for i in range(len(collators))]\n",
    "    for item in data:\n",
    "        for i in range(len(collators)):\n",
    "            batches[i].append(item[i])\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i, collator in enumerate(collators):\n",
    "        result.append(collator(batches[i]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate = lambda data: multicollate(\n",
    "    data,\n",
    "    lambda x: collate_meshes(x, device='cuda:3'),\n",
    "    lambda x: collate_meshes(x, device='cuda:3'),\n",
    "    lambda x: collate_clouds(x, device='cuda:3'),\n",
    "    lambda x: collate_clouds(x, device='cuda:3'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace.datasets.transforms import *\n",
    "\n",
    "pdataset_train = DoubleDataset(data_path='abc_train.hdf5', modality=Modality.POINT_CLOUD,\n",
    "                            transform=Compose(\n",
    "        PointCloudNormalize(),\n",
    "        RandomRotation(low=-45, high=45, axis='xyz'),\n",
    "        RandomJitter(std=0.01, clip_bound=0.05)\n",
    "    ),)\n",
    "mdataset_train = DoubleDataset(data_path='abc_train.hdf5', modality=Modality.MESH,\n",
    "                            transform=Compose(\n",
    "        MeshNetRandomRotation(low=-45, high=45, axis='xyz'),\n",
    "        MeshNetRandomJitter(std=0.01, clip_bound=0.05)\n",
    "    ),)\n",
    "\n",
    "train = DoubleModalityDataset(mdataset_train, pdataset_train)\n",
    "\n",
    "\n",
    "pdataset_test = DoubleDataset(data_path='abc_train.hdf5', modality=Modality.POINT_CLOUD,\n",
    "                            transform=PointCloudNormalize())\n",
    "mdataset_test = DoubleDataset(data_path='abc_train.hdf5', modality=Modality.MESH)\n",
    "\n",
    "test = DoubleModalityDataset(mdataset_test, pdataset_test)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=4, shuffle=False,\n",
    "               collate_fn=collate\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test, batch_size=4, shuffle=False,\n",
    "              collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ac0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# def contrastive_loss(v1_emb, v2_emb, params):\n",
    "#     device = v1_emb.device\n",
    "#     v1_emb = F.normalize(v1_emb, dim=-1)\n",
    "#     v2_emb = F.normalize(v2_emb, dim=-1)\n",
    "    \n",
    "#     v1_logits = v1_emb @ v2_emb.T / params['tau']\n",
    "#     v2_logits = v2_emb @ v1_emb.T / params['tau']\n",
    "    \n",
    "#     labels = torch.arange(v1_emb.shape[0]).to(device)\n",
    "    \n",
    "#     loss1 = F.cross_entropy(v1_logits, labels)\n",
    "#     loss2 = F.cross_entropy(v2_logits, labels)\n",
    "    \n",
    "#     return loss1 + loss2\n",
    "\n",
    "def contrastive_loss(v1_embeddings, v2_embeddings, params):\n",
    "    v1_embeddings = F.normalize(v1_embeddings, dim=1)\n",
    "    v2_embeddings = F.normalize(v2_embeddings, dim=1)\n",
    "\n",
    "    batch_size = v1_embeddings.size(0)\n",
    "    embs = torch.cat((v1_embeddings, v2_embeddings), dim=0)\n",
    "    logits = embs @ embs.transpose(1, 0) / params['tau']\n",
    "\n",
    "    # discard self similarities\n",
    "    mask = ~torch.eye(2 * batch_size, dtype=torch.bool, device=v1_embeddings.device)\n",
    "    logits = (logits\n",
    "              .masked_select(mask)\n",
    "              .view(2 * batch_size, 2 * batch_size - 1)\n",
    "              .contiguous()\n",
    "              )\n",
    "\n",
    "    labels = torch.cat((torch.arange(batch_size) + batch_size - 1,\n",
    "                        torch.arange(batch_size)\n",
    "                        ), dim=0).to(v1_embeddings.device)\n",
    "\n",
    "    return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61d15c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "head1 = torch.nn.Sequential(\n",
    "    Transpose(1, 2),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    Transpose(1, 2),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.ReLU(),\n",
    "    Transpose(1, 2),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    Transpose(1, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a779a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1(torch.rand((5, 512, 70))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(torch.nn.Module):\n",
    "    def __init__(self, *dims):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, data):\n",
    "        return data.transpose(*self.dims)\n",
    "    \n",
    "\n",
    "class MultiModalModel(torch.nn.Module):\n",
    "    def __init__(self, model1, model2, model_output_dim, result_dim=64, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.model1 = model1.to(device1)\n",
    "        self.model2 = model2.to(device2)\n",
    "        self.head1 = torch.nn.Sequential(\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(model_output_dim, hidden_dim),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(hidden_dim, result_dim),\n",
    "            Transpose(1, 2),\n",
    "        ).to(device1)\n",
    "        \n",
    "        self.head2 = torch.nn.Sequential(\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(model_output_dim, hidden_dim),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(hidden_dim, result_dim),\n",
    "            Transpose(1, 2),\n",
    "        ).to(device2)\n",
    "        \n",
    "        \n",
    "    def forward(self, input1_1, input1_2, input2_1, input2_2):\n",
    "        v1_1_emb = self.model1.forward_features(input1_1)\n",
    "        v1_2_emb = self.model1.forward_features(input1_2)\n",
    "        v2_1_emb = self.model2.forward_features(input2_1)\n",
    "        v2_2_emb = self.model2.forward_features(input2_2)\n",
    "        \n",
    "        \n",
    "        return (\n",
    "            self.head1(v1_1_emb).mean(-1),\n",
    "            self.head1(v1_2_emb).mean(-1),\n",
    "            self.head2(v2_1_emb).mean(-1),\n",
    "            self.head2(v2_2_emb).mean(-1)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def get_embeddings(self, input1_1, input1_2, input2_1, input2_2):\n",
    "        v1_1_emb = self.model1.forward_features(input1_1)\n",
    "        v1_2_emb = self.model1.forward_features(input1_2)\n",
    "        v2_1_emb = self.model2.forward_features(input2_1)\n",
    "        v2_2_emb = self.model2.forward_features(input2_2)\n",
    "        \n",
    "        return v1_1_emb, v1_2_emb, v2_1_emb, v2_2_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f22e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace.models.meshnet import MeshNet\n",
    "from workspace.models.dgcnn import DGCNN\n",
    "\n",
    "mnet = MeshNet(n_patches=5)\n",
    "dgcnn = DGCNN(n_patches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b80e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device1, device2 = 'cuda:3', 'cuda:3'\n",
    "model = MultiModalModel(mnet, dgcnn, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a36632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(\n",
    "    model,\n",
    "    batch, # raw data from dataloader\n",
    "    logger, # neptune run\n",
    "    mode # 'train'/'val'\n",
    "): # -> loss\n",
    "\n",
    "    data1_1, data1_2, data2_1, data2_2 = batch\n",
    "\n",
    "    out1_1, out1_2, out2_1, out2_2 = model(data1_1, data1_2, data2_1, data2_2)\n",
    "    \n",
    "    \n",
    "    crossmodal_loss = contrastive_loss(out1_1, out2_1, params) +\\\n",
    "           contrastive_loss(out1_2, out2_2, params) +\\\n",
    "           contrastive_loss(out1_1, out2_2, params) +\\\n",
    "           contrastive_loss(out1_2, out2_1, params)\n",
    "    \n",
    "    pc_loss = contrastive_loss(out1_1, out1_2, params)\n",
    "    mesh_loss = contrastive_loss(out2_1, out2_2, params)\n",
    "    \n",
    "    \n",
    "    return {'loss': 0.25 * crossmodal_loss + pc_loss + mesh_loss,\n",
    "            'pc_loss': pc_loss,\n",
    "            'mesh_loss': mesh_loss,\n",
    "            'crossmodal_loss:': crossmodal_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca2ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "from workspace.utils.train_loop import *\n",
    "\n",
    "params = {\n",
    "    'name': 'Experiment_multimodal_abc',\n",
    "    'dataset': 'abc',\n",
    "    'batch_size': 8,\n",
    "    'tau': 0.07,\n",
    "    'n_output': 512,\n",
    "    'total_epochs': 100,\n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 1e-5,\n",
    "    'save_every': 100,\n",
    "    'weights_root': '../weights/'\n",
    "}\n",
    "\n",
    "# tags\n",
    "tags = ['abc']\n",
    "\n",
    "# devices\n",
    "device1 = 'cuda:3'\n",
    "device2 = 'cuda:3'\n",
    "\n",
    "\n",
    "logger = neptune.init(project='seals5454/crossmodal-exps-igor',\n",
    "                      name=params['name'],\n",
    "                      tags=tags,\n",
    "                      api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmU'\\\n",
    "                                'uYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS'\\\n",
    "                                '5haSIsImFwaV9rZXkiOiI2NTIwODVkNC1hOTg5LTQ4NTAtY'\\\n",
    "                                'WRhNS0yMGY4MmQ1YzBmZWIifQ=='\n",
    "                      )\n",
    "\n",
    "logger['parameters'] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a24bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=params['lr'],\n",
    "    weight_decay=params['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * params['total_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c132d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model(model, params, logger,  train_loader, test_loader, optimizer, scheduler, forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edbd16",
   "metadata": {},
   "source": [
    "ВИЗУАЛИЗАЦИЯ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6750e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from workspace.datasets.transforms import *\n",
    "\n",
    "\n",
    "\n",
    "def visualize_elements_heatmap_pc(point_cloud, features, anchor_idx=-1):\n",
    "    '''\n",
    "    :param point_cloud: point cloud, tensor of size (n_points, 3)\n",
    "    :param features: point cloud features, tensor of size (n_points, emb_dim)\n",
    "    '''\n",
    "    if anchor_idx == -1:\n",
    "        anchor_idx = np.random.randint(0, point_cloud.size(0), size=(1,))[0]\n",
    "        \n",
    "    features = F.normalize(features, dim=-1)\n",
    "                \n",
    "    sims = features[anchor_idx] @ features.t()\n",
    "    plot = k3d.plot()\n",
    "    plot += k3d.points(point_cloud, point_size=0.025, attribute=sims)\n",
    "    plot += k3d.points(point_cloud[anchor_idx].unsqueeze(0), point_size=0.05)\n",
    "\n",
    "    return plot\n",
    "\n",
    "\n",
    "def visualize_elements_heatmap_mesh(mesh, features, anchor_idx=-1):\n",
    "    '''\n",
    "    :param mesh: tuple (vertices, faces)\n",
    "    :param features: faces features, tensor of size (>=n_faces, emb_dim)\n",
    "    '''\n",
    "    vertices, faces = mesh\n",
    "    vertices = PointCloudNormalize()(vertices)\n",
    "    faces_num = faces.shape[0]\n",
    "    features = features[:faces_num]\n",
    "    \n",
    "    if anchor_idx == -1:\n",
    "        anchor_idx = np.random.randint(0, faces_num, size=(1,))[0]\n",
    "        \n",
    "    features = F.normalize(features, dim=-1)\n",
    "    sims = features[anchor_idx] @ features.t()\n",
    "    plot = k3d.plot()\n",
    "    \n",
    "    anchor_face = faces[anchor_idx]\n",
    "    anchor_point = (vertices[anchor_face[0]] +\n",
    "                    vertices[anchor_face[1]] +\n",
    "                    vertices[anchor_face[2]]) / 3\n",
    "    plot += k3d.mesh(vertices, faces, triangles_attribute=sims[:faces.shape[0]])\n",
    "    plot += k3d.points(anchor_point[None, ...], point_size=0.1, color=0xff0000)\n",
    "    \n",
    "    return plot\n",
    "\n",
    "\n",
    "def visualize_elements_heatmap_pc_to_mesh(point_cloud, mesh, features_pc, features_mesh, anchor_idx=-1):\n",
    "    '''\n",
    "    :param point_cloud: point cloud, tensor of size (n_points, 3)\n",
    "    :param mesh: tuple (vertices, faces)\n",
    "    :param features_pc: point cloud features, tensor of size (n_points, emb_dim)\n",
    "    :param features_mesh: faces features, tensor of size (>=n_faces, emb_dim)\n",
    "    '''\n",
    "    vertices, faces = mesh\n",
    "    faces_num = faces.shape[0]\n",
    "    features_mesh = features_mesh[:faces_num]\n",
    "    features_mesh = F.normalize(features_mesh, dim=-1)\n",
    "    features_pc = F.normalize(features_pc, dim=-1)\n",
    "    \n",
    "    \n",
    "    if anchor_idx == -1:\n",
    "        anchor_idx = np.random.randint(0, point_cloud.size(0), size=(1,))[0]\n",
    "        \n",
    "    sims_pc = features_pc[anchor_idx] @ features_pc.T\n",
    "    sims_mesh = features_pc[anchor_idx] @ features_mesh.T\n",
    "    plot = k3d.plot()\n",
    "    vertices = PointCloudNormalize()(vertices)\n",
    "    vertices[:, 0] += 2\n",
    "    \n",
    "    plot += k3d.mesh(vertices, faces, triangles_attribute=sims_mesh)\n",
    "    plot += k3d.points(point_cloud, point_size=0.025, attribute=sims_pc)\n",
    "    plot += k3d.points(point_cloud[anchor_idx].unsqueeze(0), point_size=0.1, color=0xff0000)\n",
    "\n",
    "    return plot\n",
    "\n",
    "\n",
    "def visualize_elements_heatmap_mesh_to_pc(point_cloud, mesh, features_pc, features_mesh, anchor_idx=-1):\n",
    "    '''\n",
    "    :param point_cloud: point cloud, tensor of size (n_points, 3)\n",
    "    :param mesh: tuple (vertices, faces)\n",
    "    :param features_pc: point cloud features, tensor of size (n_points, emb_dim)\n",
    "    :param features_mesh: faces features, tensor of size (>=n_faces, emb_dim)\n",
    "    '''\n",
    "    vertices, faces = mesh\n",
    "    faces_num = faces.shape[0]\n",
    "    features_mesh = features_mesh[:faces_num]\n",
    "    features_mesh = F.normalize(features_mesh, dim=-1)\n",
    "    features_pc = F.normalize(features_pc, dim=-1)\n",
    "    \n",
    "    \n",
    "    if anchor_idx == -1:\n",
    "        anchor_idx = np.random.randint(0, faces_num, size=(1,))[0]\n",
    "        \n",
    "    sims_pc = features_mesh[anchor_idx] @ features_pc.T\n",
    "    sims_mesh = features_mesh[anchor_idx] @ features_mesh.T\n",
    "    plot = k3d.plot()\n",
    "    vertices = PointCloudNormalize()(vertices)\n",
    "    vertices[:, 0] += 2\n",
    "    \n",
    "    anchor_face = faces[anchor_idx]\n",
    "    anchor_point = (vertices[anchor_face[0]] +\n",
    "                    vertices[anchor_face[1]] +\n",
    "                    vertices[anchor_face[2]]) / 3\n",
    "    \n",
    "    plot += k3d.mesh(vertices, faces, triangles_attribute=sims_mesh)\n",
    "    plot += k3d.points(point_cloud, point_size=0.025, attribute=sims_pc)\n",
    "    plot += k3d.points(anchor_point[None, ...], point_size=0.1, color=0xff0000)\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1e172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8dfec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "\n",
    "feats = model.get_embeddings(*next(iter(test_loader)))\n",
    "point_cloud = next(iter(test_loader))[3][index].T.cpu()\n",
    "pc_features = feats[3][index].T.detach().cpu()\n",
    "m_features = feats[0][index].T.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('abc_train.hdf5', 'r') as h5r:\n",
    "    mesh = h5r['vertices'][index][:].reshape(-1, 3), h5r['faces'][index][:].reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dcf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_elements_heatmap_pc_to_mesh(point_cloud, mesh, pc_features, m_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63342f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_elements_heatmap_mesh_to_pc(point_cloud, mesh, pc_features, m_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4d648",
   "metadata": {},
   "source": [
    "Активации при оверфите"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99152b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    activations = model.get_embeddings(*batch)\n",
    "    fm1, fm2, fp1, fp2 = activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e249533",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 = F.normalize(fm1.mean(-1).detach().cpu(), dim=-1)\n",
    "fm2 = F.normalize(fm2.mean(-1).detach().cpu(), dim=-1)\n",
    "fp1 = F.normalize(fp1.mean(-1).detach().cpu(), dim=-1)\n",
    "fp2 = F.normalize(fp2.mean(-1).detach().cpu(), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb44690",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 @ fm2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb71dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp1 @ fp2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 @ fp1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e12918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
