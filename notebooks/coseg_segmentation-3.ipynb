{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb53b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "# Path to workspace\n",
    "sys.path.insert(0, '/workspace/dense-self-supervised-representation-learning-for-3D-shapes/')\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13f832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/neptune/new/internal/utils/git.py:35: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n",
      "/opt/conda/lib/python3.8/site-packages/neptune/new/internal/utils/git.py:35: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/igor3661/crossmodal/e/CROSS-216\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "from workspace.utils.train_loop import *\n",
    "\n",
    "params = {\n",
    "    'name': 'coseg_sem',\n",
    "    'dataset': 'modelnet',\n",
    "    'batch_size': 10,\n",
    "    'tau': 0.07,\n",
    "    'n_output': 512,\n",
    "    'result_dim': 3,\n",
    "    'hidden_dim': 256,\n",
    "    'total_epochs': 100,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-5,\n",
    "    'save_every': 50,\n",
    "    'weights_root': 'weights/'\n",
    "}\n",
    "\n",
    "tags = ['coseg', 'segmentation']\n",
    "\n",
    "logger = neptune.init(\n",
    "    project=\"igor3661/crossmodal\",\n",
    "    name=params['name'],\n",
    "    tags=tags,\n",
    "    api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcG'\\\n",
    "              'lfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiN'\\\n",
    "              'zcxMGNkOS04ZjU3LTRmNDMtOWFjMS1kNDNkZDZlNDI4YWYifQ==',\n",
    ")  # your credentials\n",
    "\n",
    "\n",
    "logger['parameters'] = params\n",
    "\n",
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45796bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from workspace.crossmodal.utils.meshnet_preprop import *\n",
    "\n",
    "\n",
    "class PointSegDataset(Dataset):\n",
    "    def __init__(self, data_path, indexes=None, transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.indexes = indexes\n",
    "        self.file = h5py.File(data_path, 'r')\n",
    "\n",
    "    def __getitem__(self, index):  \n",
    "        index = self.indexes[index]\n",
    "        points = self.file['points'][index][:]\n",
    "        labels = self.file['points_labels'][index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            points = self.transform(points)\n",
    "\n",
    "        points = torch.from_numpy(points).float()\n",
    "        points = torch.permute(points, (1, 0))\n",
    "        return points, labels\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n",
    "    \n",
    "    \n",
    "class MeshnetSegDataset(Dataset):\n",
    "    def __init__(self, data_path, indexes=None, rotation=None, jitter=None):\n",
    "        super().__init__()\n",
    "        self.rotation = rotation\n",
    "        self.indexes = indexes\n",
    "        self.jitter = jitter\n",
    "        self.file = h5py.File(data_path, 'r')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indexes[index]\n",
    "        faces = self.file['faces'][index][:].reshape(-1, 3)\n",
    "        vertices = self.file['vertices'][index][:].reshape(-1, 3)\n",
    "        labels = self.file['faces_labels'][index]\n",
    "        \n",
    "        \n",
    "        if self.rotation is not None:\n",
    "            vertices = self.rotation(vertices)\n",
    "        \n",
    "        features, neighbors = process_mesh(faces, vertices)\n",
    "        \n",
    "\n",
    "        features = torch.from_numpy(features).float()\n",
    "        neighbors = torch.from_numpy(neighbors).long()\n",
    "        labels = torch.from_numpy(labels).long()\n",
    "\n",
    "        features = torch.permute(features, (1, 0))\n",
    "        centers, corners, normals = features[:3], features[3:12], features[12:]\n",
    "        \n",
    "        if self.jitter is not None:\n",
    "            centers = self.jitter(centers).float()\n",
    "        \n",
    "        corners = corners - torch.cat([centers, centers, centers], 0).float()\n",
    "        \n",
    "        num_faces = neighbors.shape[0]\n",
    "        if num_faces < 500:\n",
    "            fill_idx = np.random.choice(num_faces, 500 - num_faces)\n",
    "            centers = (torch.cat([centers, centers[:, fill_idx]], dim=1))\n",
    "            corners = (torch.cat([corners, corners[:, fill_idx]], dim=1))\n",
    "            normals = (torch.cat([normals, normals[:, fill_idx]], dim=1))\n",
    "            neighbors = (torch.cat([neighbors, neighbors[fill_idx]]))\n",
    "            labels = (torch.cat([labels, labels[fill_idx]]))\n",
    "\n",
    "        return centers, corners, normals, neighbors, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63d4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'chairs.h5'\n",
    "\n",
    "with h5py.File(DATASET, 'r') as h5:\n",
    "    N_CLASSES = len(np.unique(h5['points_labels'][:]))\n",
    "    LENGTH = h5['points_labels'].shape[0]\n",
    "    split = np.random.permutation(LENGTH)\n",
    "    train_indexes = split[:int(0.05 * LENGTH) + 1]\n",
    "    test_indexes = split[int(0.05 * LENGTH) + 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29689f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MeshnetSegDataset(DATASET, indexes=train_indexes)\n",
    "test_data = MeshnetSegDataset(DATASET, indexes=test_indexes)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=params['batch_size'],\n",
    "    num_workers=10,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    shuffle=False,\n",
    "    batch_size=params['batch_size'],\n",
    "    num_workers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610c0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(torch.nn.Module):\n",
    "    def __init__(self, *dims):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, data):\n",
    "        return data.transpose(*self.dims)\n",
    "    \n",
    "\n",
    "class NormalsModel(torch.nn.Module):\n",
    "    def __init__(self, model, model_output_dim, result_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.head = torch.nn.Sequential(\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(model_output_dim, hidden_dim),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            Transpose(1, 2),\n",
    "            torch.nn.Linear(hidden_dim, 128),\n",
    "            Transpose(1, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.head(self.model.forward_features(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54c8063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from workspace.models.dgcnn import DGCNN\n",
    "from workspace.models.meshnet import MeshNet\n",
    "\n",
    "meshnet = MeshNet(n_patches=5)\n",
    "\n",
    "model = NormalsModel(\n",
    "    meshnet,\n",
    "    model_output_dim=params['n_output'],\n",
    "    hidden_dim=params['hidden_dim'],\n",
    "    result_dim=params['result_dim']\n",
    ").to(device).eval()\n",
    "\n",
    "model.load_state_dict(torch.load('weights/CROSS-64/100epoch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228155b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = torch.nn.Sequential(\n",
    "    Transpose(1, 2),\n",
    "    torch.nn.Linear(params['n_output'], params['n_output'] // 2),\n",
    "    Transpose(1, 2),\n",
    "    torch.nn.BatchNorm1d(params['n_output'] // 2),\n",
    "    torch.nn.ReLU(),\n",
    "    Transpose(1, 2),\n",
    "    torch.nn.Linear(params['n_output'] // 2, N_CLASSES),\n",
    "    Transpose(1, 2),\n",
    ")\n",
    "\n",
    "model.head = head.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4e521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projector(torch.nn.Module):\n",
    "    def __init__(self, model_output_dim):\n",
    "        super().__init__()\n",
    "        self.head = torch.nn.Sequential(\n",
    "                Transpose(1, 2),\n",
    "                torch.nn.Linear(model_output_dim + 3, model_output_dim * 2),\n",
    "                Transpose(1, 2),\n",
    "                torch.nn.BatchNorm1d(model_output_dim * 2),\n",
    "                torch.nn.ReLU(),\n",
    "                Transpose(1, 2),\n",
    "                torch.nn.Linear(model_output_dim * 2, model_output_dim),\n",
    "                Transpose(1, 2),\n",
    "            )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        return self.head(data)\n",
    "    \n",
    "proj = Projector(params['n_output']).to(device)\n",
    "proj.load_state_dict(torch.load('weights/CROSS-75/100epoch.pt'))\n",
    "model.proj = proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0686a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def move_to_device(data, device='cpu'):\n",
    "    if isinstance(data, list):\n",
    "        return [item.to(device) for item in data]\n",
    "    else:\n",
    "        return data.to(device)\n",
    "\n",
    "\n",
    "def forward_clouds( \n",
    "    model,\n",
    "    batch, # raw data from dataloader\n",
    "    logger, # neptune run\n",
    "    mode # 'train'/'val'\n",
    "): # -> loss\n",
    "\n",
    "    batch = move_to_device(batch, device)\n",
    "    \n",
    "    points = batch[0]\n",
    "    labels = batch[1]\n",
    "        \n",
    "    out = model(points)\n",
    "        \n",
    "    loss = F.cross_entropy(out, labels.long())\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'loss': loss\n",
    "    }\n",
    "\n",
    "def forward_meshes( \n",
    "    model,\n",
    "    batch, # raw data from dataloader\n",
    "    logger, # neptune run\n",
    "    mode # 'train'/'val'\n",
    "): # -> loss\n",
    "    \n",
    "    batch = move_to_device(batch, device)\n",
    "    \n",
    "    meshes = batch[0:4]\n",
    "    labels = batch[4]\n",
    "        \n",
    "    out = model(meshes)\n",
    "        \n",
    "    loss = F.cross_entropy(out, labels.long())\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'loss': loss\n",
    "    }\n",
    "\n",
    "def forward_proj(\n",
    "    model,\n",
    "    batch, # raw data from dataloader\n",
    "    logger, # neptune run\n",
    "    mode\n",
    "):\n",
    "    batch = move_to_device(batch, device)\n",
    "    \n",
    "    meshes = batch[0:4]\n",
    "    centers = meshes[0]\n",
    "    labels = batch[4]\n",
    "        \n",
    "    out = model.model.forward_features(meshes)\n",
    "    \n",
    "    out = torch.cat([out, centers], dim=1)\n",
    "    \n",
    "    out = model.head(model.proj(out))\n",
    "        \n",
    "    loss = F.cross_entropy(out, labels.long())\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'loss': loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e41bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=params['lr'],\n",
    "    weight_decay=params['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * params['total_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea6b5c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.04s/it, Epoch=1, Loss=0.979]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.53it/s, Loss=0.906]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.07s/it, Epoch=2, Loss=0.659]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.86it/s, Loss=0.78] \n",
      "100%|██████████| 2/2 [00:01<00:00,  1.01it/s, Epoch=3, Loss=0.51] \n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.99it/s, Loss=0.73] \n",
      "100%|██████████| 2/2 [00:02<00:00,  1.08s/it, Epoch=4, Loss=0.438]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.27it/s, Loss=0.668]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.21s/it, Epoch=5, Loss=0.373]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.04it/s, Loss=0.645]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.32s/it, Epoch=6, Loss=0.338]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.88it/s, Loss=0.634]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.24s/it, Epoch=7, Loss=0.299]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.06it/s, Loss=0.613]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.30s/it, Epoch=8, Loss=0.261]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.83it/s, Loss=0.585]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.35s/it, Epoch=9, Loss=0.239]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.15it/s, Loss=0.556]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.43s/it, Epoch=10, Loss=0.197]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.17it/s, Loss=0.554]\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.52s/it, Epoch=11, Loss=0.181]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.81it/s, Loss=0.56] \n",
      "100%|██████████| 2/2 [00:02<00:00,  1.32s/it, Epoch=12, Loss=0.159]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.74it/s, Loss=0.586]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.29s/it, Epoch=13, Loss=0.152]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.79it/s, Loss=0.607]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.28s/it, Epoch=14, Loss=0.156]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.13it/s, Loss=0.565]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.35s/it, Epoch=15, Loss=0.131]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.02it/s, Loss=0.566]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.34s/it, Epoch=16, Loss=0.108]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.50it/s, Loss=0.579]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.20s/it, Epoch=17, Loss=0.0961]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.56it/s, Loss=0.584]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.10s/it, Epoch=18, Loss=0.0957]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.38it/s, Loss=0.572]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.21s/it, Epoch=19, Loss=0.0782]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.85it/s, Loss=0.561]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.29s/it, Epoch=20, Loss=0.0655]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.77it/s, Loss=0.566]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.31s/it, Epoch=21, Loss=0.079] \n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.04it/s, Loss=0.579]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.20s/it, Epoch=22, Loss=0.0575]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.54it/s, Loss=0.568]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.12s/it, Epoch=23, Loss=0.0591]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.80it/s, Loss=0.581]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.19s/it, Epoch=24, Loss=0.0514]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.80it/s, Loss=0.597]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.15s/it, Epoch=25, Loss=0.0448]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.61it/s, Loss=0.615]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.25s/it, Epoch=26, Loss=0.0451]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.36it/s, Loss=0.635]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.23s/it, Epoch=27, Loss=0.035]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.86it/s, Loss=0.628]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.27s/it, Epoch=28, Loss=0.0286]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.47it/s, Loss=0.6]  \n",
      "100%|██████████| 2/2 [00:02<00:00,  1.24s/it, Epoch=29, Loss=0.0248]\n",
      "Validation: 100%|██████████| 38/38 [00:06<00:00,  6.30it/s, Loss=0.568]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.04s/it, Epoch=30, Loss=0.0231]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.69it/s, Loss=0.569]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.23s/it, Epoch=31, Loss=0.0264]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.78it/s, Loss=0.588]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.42s/it, Epoch=32, Loss=0.0196]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.81it/s, Loss=0.628]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.32s/it, Epoch=33, Loss=0.0223]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.73it/s, Loss=0.638]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.29s/it, Epoch=34, Loss=0.0143]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.44it/s, Loss=0.639]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.02s/it, Epoch=35, Loss=0.0149]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.86it/s, Loss=0.625]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.33s/it, Epoch=36, Loss=0.0207]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.77it/s, Loss=0.605]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.46s/it, Epoch=37, Loss=0.017] \n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.57it/s, Loss=0.597]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.17s/it, Epoch=38, Loss=0.0192]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.84it/s, Loss=0.608]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.28s/it, Epoch=39, Loss=0.0122]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.92it/s, Loss=0.636]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.15s/it, Epoch=40, Loss=0.0155]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.37it/s, Loss=0.653]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.31s/it, Epoch=41, Loss=0.00967]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.85it/s, Loss=0.662]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.33s/it, Epoch=42, Loss=0.0172]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.78it/s, Loss=0.634]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.37s/it, Epoch=43, Loss=0.0112]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.24it/s, Loss=0.613]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.41s/it, Epoch=44, Loss=0.0107]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.94it/s, Loss=0.618]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.36s/it, Epoch=45, Loss=0.00839]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.69it/s, Loss=0.638]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.41s/it, Epoch=46, Loss=0.00904]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  6.55it/s, Loss=0.659]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.42s/it, Epoch=47, Loss=0.00564]\n",
      "Validation: 100%|██████████| 38/38 [00:06<00:00,  6.33it/s, Loss=0.672]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.28s/it, Epoch=48, Loss=0.00789]\n",
      "Validation: 100%|██████████| 38/38 [00:06<00:00,  6.17it/s, Loss=0.668]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.04it/s, Epoch=49, Loss=0.00616]\n",
      "Validation: 100%|██████████| 38/38 [00:06<00:00,  6.23it/s, Loss=0.653]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.08s/it, Epoch=50, Loss=0.00682]\n",
      "Validation: 100%|██████████| 38/38 [00:06<00:00,  6.32it/s, Loss=0.645]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.01s/it, Epoch=51, Loss=0.00488]\n",
      "Validation: 100%|██████████| 38/38 [00:06<00:00,  6.11it/s, Loss=0.642]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.12s/it, Epoch=52, Loss=0.00683]\n",
      "Validation: 100%|██████████| 38/38 [00:06<00:00,  6.07it/s, Loss=0.648]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.07s/it, Epoch=53, Loss=0.00486]\n",
      "Validation: 100%|██████████| 38/38 [00:06<00:00,  6.24it/s, Loss=0.654]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.06it/s, Epoch=54, Loss=0.00602]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.03it/s, Loss=0.658]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.10it/s, Epoch=55, Loss=0.00461]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.07it/s, Loss=0.662]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.07it/s, Epoch=56, Loss=0.00536]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.27it/s, Loss=0.663]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.08it/s, Epoch=57, Loss=0.00357]\n",
      "Validation: 100%|██████████| 38/38 [00:05<00:00,  7.25it/s, Loss=0.66] \n",
      "100%|██████████| 2/2 [00:01<00:00,  1.18it/s, Epoch=58, Loss=0.00369]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.68it/s, Loss=0.66] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.08it/s, Epoch=59, Loss=0.0116]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.35it/s, Loss=0.665]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.07it/s, Epoch=60, Loss=0.00441]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  9.11it/s, Loss=0.671]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.32it/s, Epoch=61, Loss=0.00792]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.39it/s, Loss=0.68] \n",
      "100%|██████████| 2/2 [00:01<00:00,  1.07it/s, Epoch=62, Loss=0.00336]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.87it/s, Loss=0.687]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.03it/s, Epoch=63, Loss=0.00545]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.93it/s, Loss=0.678]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.00it/s, Epoch=64, Loss=0.00382]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  9.03it/s, Loss=0.672]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.10s/it, Epoch=65, Loss=0.00307]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  9.10it/s, Loss=0.67] \n",
      "100%|██████████| 2/2 [00:02<00:00,  1.12s/it, Epoch=66, Loss=0.00347]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00,  9.79it/s, Loss=0.671]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.16it/s, Epoch=67, Loss=0.00308]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.32it/s, Loss=0.675]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.10it/s, Epoch=68, Loss=0.00476]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.54it/s, Loss=0.683]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.15s/it, Epoch=69, Loss=0.00358]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.56it/s, Loss=0.691]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.10s/it, Epoch=70, Loss=0.00369]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 10.03it/s, Loss=0.691]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.02s/it, Epoch=71, Loss=0.00597]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00,  9.55it/s, Loss=0.692]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.09s/it, Epoch=72, Loss=0.00481]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00,  9.72it/s, Loss=0.691]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.10s/it, Epoch=73, Loss=0.00315]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  9.49it/s, Loss=0.687]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.01it/s, Epoch=74, Loss=0.00265]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.98it/s, Loss=0.682]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.15it/s, Epoch=75, Loss=0.00336]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  9.39it/s, Loss=0.681]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.05s/it, Epoch=76, Loss=0.00236]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  9.05it/s, Loss=0.678]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.06it/s, Epoch=77, Loss=0.00436]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  9.06it/s, Loss=0.682]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.08it/s, Epoch=78, Loss=0.00325]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.89it/s, Loss=0.676]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.03it/s, Epoch=79, Loss=0.00593]\n",
      "Validation: 100%|██████████| 38/38 [00:04<00:00,  8.63it/s, Loss=0.677]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.22it/s, Epoch=80, Loss=0.0027] \n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 10.36it/s, Loss=0.677]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.08it/s, Epoch=81, Loss=0.00361]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 10.54it/s, Loss=0.676]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.07it/s, Epoch=82, Loss=0.00363]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 10.95it/s, Loss=0.674]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.07it/s, Epoch=83, Loss=0.00208]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 10.96it/s, Loss=0.674]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.10it/s, Epoch=84, Loss=0.00304]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 10.79it/s, Loss=0.677]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.11it/s, Epoch=85, Loss=0.00296]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 11.02it/s, Loss=0.679]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.23it/s, Epoch=86, Loss=0.00387]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 13.59it/s, Loss=0.683]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.41it/s, Epoch=87, Loss=0.00326]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 12.55it/s, Loss=0.686]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.22it/s, Epoch=88, Loss=0.00323]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 13.44it/s, Loss=0.684]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.33it/s, Epoch=89, Loss=0.00235]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 13.61it/s, Loss=0.682]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.21it/s, Epoch=90, Loss=0.00203]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 12.72it/s, Loss=0.681]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.16it/s, Epoch=91, Loss=0.00237]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 13.60it/s, Loss=0.678]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.27it/s, Epoch=92, Loss=0.00297]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 12.95it/s, Loss=0.678]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.21it/s, Epoch=93, Loss=0.00231]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 12.79it/s, Loss=0.678]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.09it/s, Epoch=94, Loss=0.0029] \n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 13.30it/s, Loss=0.682]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.28it/s, Epoch=95, Loss=0.00218]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 12.71it/s, Loss=0.682]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.11it/s, Epoch=96, Loss=0.00499]\n",
      "Validation: 100%|██████████| 38/38 [00:03<00:00, 12.59it/s, Loss=0.684]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.19it/s, Epoch=97, Loss=0.00246]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 12.77it/s, Loss=0.679]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.21it/s, Epoch=98, Loss=0.00667]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 18.04it/s, Loss=0.682]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.96it/s, Epoch=99, Loss=0.00326]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 16.12it/s, Loss=0.682]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.16it/s, Epoch=100, Loss=0.00412]\n",
      "Validation: 100%|██████████| 38/38 [00:02<00:00, 18.77it/s, Loss=0.681]\n"
     ]
    }
   ],
   "source": [
    "train_model(model, params, logger,  train_loader, test_loader, optimizer, scheduler, forward_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c427b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_preds_targets_clouds(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for points, labels in tqdm(loader):\n",
    "        out = model(points.to(device)).cpu()\n",
    "        preds.append(torch.max(out, dim=1).indices)\n",
    "        targets.append(labels)\n",
    "        \n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    return preds, targets\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_preds_targets_meshes(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for centers, corners, normals, neighbors, labels in tqdm(loader):\n",
    "        out = model([centers.to(device), corners.to(device), normals.to(device), neighbors.to(device)]).cpu()\n",
    "        preds.append(torch.max(out, dim=1).indices)\n",
    "        targets.append(labels)\n",
    "        \n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    return preds, targets\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_preds_targets_proj(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for centers, corners, normals, neighbors, labels in tqdm(loader):\n",
    "        centers = centers.to(device)\n",
    "        corners = corners.to(device)\n",
    "        normals = normals.to(device)\n",
    "        neighbors = neighbors.to(device)\n",
    "        out = model.model.forward_features([centers, corners, normals, neighbors])\n",
    "        out = torch.cat([out, centers], dim=1)\n",
    "        out = model.head(model.proj(out))\n",
    "        \n",
    "        preds.append(torch.max(out, dim=1).indices)\n",
    "        targets.append(labels)\n",
    "        \n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    return preds, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac3e6177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:02<00:00, 18.12it/s]\n"
     ]
    }
   ],
   "source": [
    "p, l = get_preds_targets_proj(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f87a745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIOU(label, pred, num_classes=N_CLASSES):\n",
    "    iou_list = list()\n",
    "    present_iou_list = list()\n",
    "\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "    # Note: Following for loop goes from 0 to (num_classes-1)\n",
    "    # and ignore_index is num_classes, thus ignore_index is\n",
    "    # not considered in computation of IoU.\n",
    "    for sem_class in range(num_classes):\n",
    "        pred_inds = (pred == sem_class)\n",
    "        target_inds = (label == sem_class)\n",
    "        if target_inds.long().sum().item() == 0:\n",
    "            iou_now = float('nan')\n",
    "        else: \n",
    "            intersection_now = (pred_inds[target_inds]).long().sum().item()\n",
    "            union_now = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection_now\n",
    "            iou_now = float(intersection_now) / float(union_now)\n",
    "            present_iou_list.append(iou_now)\n",
    "        iou_list.append(iou_now)\n",
    "    return np.mean(present_iou_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63e4b384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7346146933486213"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mIOU(l, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ad7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2247e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9f432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9208a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e013e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_PARTS = 4\n",
    "# N_CLASSES = 1\n",
    "# NUM_POINT = 1024\n",
    "\n",
    "# seg_classes = {'Aliens': [0, 1, 2, 3]}\n",
    "# seg_label_to_cat = {0: 'Aliens'}\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def calc_metrics(model, loader, device):\n",
    "#     model.eval()\n",
    "#     test_metrics = {}\n",
    "#     total_correct = 0\n",
    "#     total_seen = 0\n",
    "#     total_seen_class = [0 for _ in range(N_PARTS)]\n",
    "#     total_correct_class = [0 for _ in range(N_PARTS)]\n",
    "#     shape_ious = {cat: [] for cat in seg_classes.keys()}\n",
    "\n",
    "#     for batch_id, (points, label) in tqdm(enumerate(loader), total=len(loader)):\n",
    "#         target = torch.zeros(points.shape[0])\n",
    "#         cur_batch_size, _, NUM_POINT = points.size()\n",
    "#         points, label, target = points.to(device), label.long().to(device), target.long()\n",
    "\n",
    "#         seg_pred = model(points.to(device)).transpose(2, 1)\n",
    "\n",
    "#         cur_pred_val = seg_pred.cpu().data.numpy()\n",
    "#         cur_pred_val_logits = cur_pred_val\n",
    "#         cur_pred_val = np.zeros((cur_batch_size, NUM_POINT)).astype(np.int32)\n",
    "#         target = target.data.numpy()\n",
    "\n",
    "#         for i in range(cur_batch_size):\n",
    "#             cat = seg_label_to_cat[target[i, 0]]\n",
    "#             logits = cur_pred_val_logits[i, :, :]\n",
    "#             cur_pred_val[i, :] = np.argmax(logits[:, seg_classes[cat]], 1) + seg_classes[cat][0]\n",
    "\n",
    "#         correct = np.sum(cur_pred_val == target)\n",
    "#         total_correct += correct\n",
    "#         total_seen += (cur_batch_size * NUM_POINT)\n",
    "\n",
    "#         for l in range(N_PARTS):\n",
    "#             total_seen_class[l] += np.sum(target == l)\n",
    "#             total_correct_class[l] += (np.sum((cur_pred_val == l) & (target == l)))\n",
    "\n",
    "#         for i in range(cur_batch_size):\n",
    "#             segp = cur_pred_val[i, :]\n",
    "#             segl = target[i, :]\n",
    "#             cat = seg_label_to_cat[segl[0]]\n",
    "#             part_ious = [0.0 for _ in range(len(seg_classes[cat]))]\n",
    "#             for l in seg_classes[cat]:\n",
    "#                 if (np.sum(segl == l) == 0) and (\n",
    "#                         np.sum(segp == l) == 0):  # part is not present, no prediction as well\n",
    "#                     part_ious[l - seg_classes[cat][0]] = 1.0\n",
    "#                 else:\n",
    "#                     part_ious[l - seg_classes[cat][0]] = np.sum((segl == l) & (segp == l)) / float(\n",
    "#                         np.sum((segl == l) | (segp == l)))\n",
    "#             shape_ious[cat].append(np.mean(part_ious))\n",
    "\n",
    "#     all_shape_ious = []\n",
    "#     for cat in shape_ious.keys():\n",
    "#         for iou in shape_ious[cat]:\n",
    "#             all_shape_ious.append(iou)\n",
    "#         shape_ious[cat] = np.mean(shape_ious[cat])\n",
    "\n",
    "#     mean_shape_ious = np.mean(list(shape_ious.values()))\n",
    "#     test_metrics['accuracy'] = total_correct / float(total_seen)\n",
    "#     test_metrics['class_avg_accuracy'] = np.mean(\n",
    "#         np.array(total_correct_class) / np.array(total_seen_class, dtype=float))\n",
    "\n",
    "#     for cat in sorted(shape_ious.keys()):\n",
    "#         print('eval mIoU of %s %f' % (cat + ' ' * (14 - len(cat)), shape_ious[cat]))\n",
    "\n",
    "#     test_metrics['class_avg_iou'] = mean_shape_ious\n",
    "#     test_metrics['instance_avg_iou'] = np.mean(all_shape_ious)\n",
    "\n",
    "#     print('Accuracy is: %.5f' % test_metrics['accuracy'])\n",
    "#     print('Class avg accuracy is: %.5f' % test_metrics['class_avg_accuracy'])\n",
    "#     print('Class avg mIOU is: %.5f' % test_metrics['class_avg_iou'])\n",
    "#     print('Instance avg mIOU is: %.5f' % test_metrics['instance_avg_iou'])\n",
    "\n",
    "#     return test_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
